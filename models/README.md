# ğŸ“Š Modelos

Resumen de los modelos entrenados por nosotros y utilizados en el proyecto.

## ğŸ“· Components PC Model

`components_pc_model.keras`

La arquitectura del modelo se basa en una **Red Neuronal Convolucional (CNN)** construida con **Keras**, que incluye mÃºltiples capas de convoluciÃ³n, normalizaciÃ³n, pooling y capas densas, finalizando con una capa **softmax** para clasificaciÃ³n multiclase. 

| ğŸ§© Layer (type)                           | Output Shape         | Param # |
| ----------------------------------------- | -------------------- | ------- |
| ğŸŸ¦ **conv2d_20 (Conv2D)**                 | (None, 230, 230, 16) | 160     |
| ğŸŸª **batch_normalization_10 (BatchNorm)** | (None, 230, 230, 16) | 64      |
| ğŸŸ© **max_pooling2d_25 (MaxPooling2D)**    | (None, 115, 115, 16) | 0       |
| ğŸŸ¦ **conv2d_21 (Conv2D)**                 | (None, 115, 115, 32) | 4,640   |
| ğŸŸª **batch_normalization_11 (BatchNorm)** | (None, 115, 115, 32) | 128     |
| ğŸŸ© **max_pooling2d_26 (MaxPooling2D)**    | (None, 57, 57, 32)   | 0       |
| ğŸŸ¦ **conv2d_22 (Conv2D)**                 | (None, 57, 57, 64)   | 18,496  |
| ğŸŸª **batch_normalization_12 (BatchNorm)** | (None, 57, 57, 64)   | 256     |
| ğŸŸ© **max_pooling2d_27 (MaxPooling2D)**    | (None, 28, 28, 64)   | 0       |
| ğŸŸ¨ **global_average_pooling2d (GAP)**     | (None, 64)           | 0       |
| ğŸ”´ **dropout_16 (Dropout)**               | (None, 64)           | 0       |
| ğŸŸ§ **dense_24 (Dense)**                   | (None, 64)           | 4,160   |
| ğŸ”´ **dropout_17 (Dropout)**               | (None, 64)           | 0       |
| ğŸŸ§ **dense_25 (Dense)**                   | (None, 11)           | 715     |

- **ğŸ“ Total params:** 28,619 (â‰ˆ111.79 KB)
- **âš¡ Trainable params:** 28,395 (â‰ˆ110.92 KB)
- **âŒ Non-trainable params:** 224 (â‰ˆ896 B)


### ğŸ·ï¸ Clasificacion

```python
label_map = {
    0: 'motherboard',
    1: 'gpu',
    2: 'cpu',
    3: 'hard_drive',
    4: 'ram',
    5: 'pc_case',
    6: 'power_supply',
    7: 'liquid_cooling',
    8: 'case_fan',
    9: 'cpu_fan',
    10: 'sound_card'
}
```

### Resultados de rendimiento

![performance_test](../img/models/performance_test.png)

#### EvoluciÃ³n del Entrenamiento

El modelo se entrenÃ³ durante **18 Ã©pocas** antes de que el *Early Stopping* detuviera el proceso para evitar el sobreajuste.

* **Punto de inflexiÃ³n:** Al inicio (Ã‰poca 1), el modelo apenas tenÃ­a una precisiÃ³n del **35%**. Sin embargo, se observa una mejora drÃ¡stica en la **Ã‰poca 9**, coincidiendo con la primera reducciÃ³n automÃ¡tica de la tasa de aprendizaje (*Learning Rate*).

**MÃ©tricas Finales:**
* **PrecisiÃ³n de entrenamiento:** ~82.5%
* **PrecisiÃ³n de validaciÃ³n:** **86.6%**
* **PÃ©rdida (Loss) de validaciÃ³n:** 0.5061


#### EvaluaciÃ³n con Datos de Prueba (Test)

Al evaluar el modelo con el conjunto de datos de prueba (`x_test`), los resultados confirman su solidez:

* **PrecisiÃ³n en Test (Accuracy):** **85.24%**
* **PÃ©rdida en Test:** 0.5073
* **InterpretaciÃ³n:** Una precisiÃ³n del 85% en un problema de 11 categorÃ­as.

#### AnÃ¡lisis de General

* **Eficacia del Optimizador:** El uso de `ReduceLROnPlateau` permitiÃ³ que, cuando el modelo dejÃ³ de mejorar con la tasa de aprendizaje inicial, se realizaran ajustes mÃ¡s finos (bajando de  a  y finalmente a ), lo que permitiÃ³ "pulir" la precisiÃ³n en las Ãºltimas etapas.

* **Robustez:** El modelo es capaz de manejar la descompensaciÃ³n en el dataset (donde algunas categorÃ­as tenÃ­an muy pocas imÃ¡genes, como las tarjetas de sonido) sin perder eficacia global.
* **Eficiencia:** Al procesar las imÃ¡genes en **escala de grises**, el modelo logra estos resultados con una arquitectura eficiente de 3 capas convolucionales, lo que permite predicciones rÃ¡pidas incluso en hardware no especializado.